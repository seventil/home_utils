{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных по чугунам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_excel('нейросеть.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"номер образца\"] = df[\"номер образца\"].fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# некоторые образцы нюансы типа скорости помечены в номер образца, сбросить те которые портят результаты\n",
    "\n",
    "filter_specimen = [value for value in df[\"номер образца\"].unique() if \"V 3\" in str(value)]\n",
    "df = df[~df[\"номер образца\"].isin(filter_specimen)]\n",
    "filter_specimen = [value for value in df[\"номер образца\"].unique() if \"V 0,5\" in str(value)]\n",
    "df = df[~df[\"номер образца\"].isin(filter_specimen)]\n",
    "filter_specimen = [value for value in df[\"номер образца\"].unique() if \"V 0,9\" in str(value)]\n",
    "df = df[~df[\"номер образца\"].isin(filter_specimen)]\n",
    "drop_columns = [\n",
    "    \"номер образца\", \"Образец\",\n",
    "]\n",
    "df = df.drop(columns=drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# В ходе работы обнаружили, что измерения с радиусом 115 / массой 430 были не на нежестких и таким образом оптимальные массу радиус не подобрать. \n",
    "# Нужно удалить массу и радиус лишние, и искать оптимальные параметры в других\n",
    "df = df[df['mass'] != 0.004300]\n",
    "indentor_drop_cols = [\"mass\", \"r\"]\n",
    "df = df.drop(columns=indentor_drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df_hb = df[\"HB\"]\n",
    "x_df_hb = df.drop(columns=\"HB\")\n",
    "\n",
    "x_hb_train, x_hb_test, y_hb_train, y_hb_test = train_test_split(x_df_hb, y_df_hb, \n",
    "                                                train_size=0.8, \n",
    "                                                random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hb_predictor = LinearRegression(n_jobs=-1)\n",
    "hb_predictor.fit(X=x_hb_train, y=y_hb_train)\n",
    "\n",
    "predicted_hb = hb_predictor.predict(x_hb_test)\n",
    "nevyazka_hb = hb_predictor.predict(x_hb_train)\n",
    "\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_hb_test, predicted_hb))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(y_hb_test, predicted_hb))\n",
    "plt.scatter(y_hb_train, nevyazka_hb)\n",
    "plt.scatter(y_hb_test, predicted_hb)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = hb_predictor.coef_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    " print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Энергия деформирования Дж`,\n",
    "`Энергия упругого деформирования Дж`,\n",
    "`Энергия вязкого деформирования Дж`.\n",
    "и на этом графике не видно, но при отсутствии энергий еще `e`\n",
    "\n",
    "имеют максимальное влияние на результат. Что если их убрать?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index(['расстояние от заделки', 'Жесткость по Маквеллу и Фойгту Н/м',\n",
    "       'Вязкость по Фойгту Н*с/м', 'Вязкость по Максвеллу Н*с/м',\n",
    "       'Тангенс потерь град', 'Энергия деформирования Дж',\n",
    "       'Энергия упругого деформирования Дж',\n",
    "       'Энергия вязкого деформирования Дж', 'Время удара мкс',\n",
    "       'Максимальное усилие Н', 'Максимальное внедрение мкм', 'активное_время',\n",
    "       'vmax', 'vmin', 'rigidity1', 'r', 'ost_def', 'a_p_pmax', 'p_a_amax',\n",
    "       'ugol_naklona', 'modul_po_ugly', 'mass', 'внедр_при_макс_силе',\n",
    "       'delta_force', 'угол_all', 'угол_50', 'угол_30', 'contact_depth',\n",
    "       'contact_area', 'ugol_naklona_2', 'reduced_modulus', 'P / a', 'e',\n",
    "       'Pmax/apmax', 'Pamax/amax', 'HB'],\n",
    "      dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_feature = 'расстояние от заделки'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = [\n",
    "    \"Энергия деформирования Дж\",\t\n",
    "    \"Энергия упругого деформирования Дж\",\t\n",
    "    \"Энергия вязкого деформирования Дж\",\n",
    "    \"e\",\n",
    "    class_feature\n",
    "]\n",
    "df_bf = df[best_features + [\"HB\"]]\n",
    "df_of = df.drop(columns=best_features)\n",
    "df_bf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split datasets by weird data clustering\n",
    "filter_by = \"e\"\n",
    "# filter_specimen = [value for value in df[filter_by].unique() if value < ]\n",
    "df_bf_1 = df_bf[df_bf[filter_by] <= 0.001]\n",
    "df_bf_2 = df_bf[df_bf[filter_by] > 0.001]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FULL\n",
    "sns.pairplot(df_bf, hue=class_feature, markers=[\"o\", \"s\", \"D\", \"v\", \"^\", \"<\", \">\"]) # , markers=[\"o\", \"s\", \"D\", \"v\", \"^\", \"<\", \">\"]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HEAD\n",
    "sns.pairplot(df_bf.head(592), hue=class_feature) # , markers=[\"o\", \"s\", \"D\", \"v\", \"^\", \"<\", \">\"]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAIL\n",
    "sns.pairplot(df_bf.tail(320), hue=class_feature, markers=[\"o\", \"s\", \"D\", \"v\", \"^\", \"<\", \">\"]) # , markers=[\"o\", \"s\", \"D\", \"v\", \"^\", \"<\", \">\"]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First cluster\n",
    "sns.pairplot(df_bf_1, hue=class_feature) # , markers=[\"o\", \"s\", \"D\", \"v\", \"^\", \"<\", \">\"]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second cluster\n",
    "sns.pairplot(df_bf_2, hue=class_feature) # , markers=[\"o\", \"s\", \"D\", \"v\", \"^\", \"<\", \">\"]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df_hb = df_of[\"HB\"]\n",
    "x_df_hb = df_of.drop(columns=\"HB\")\n",
    "\n",
    "x_hb_train, x_hb_test, y_hb_train, y_hb_test = train_test_split(x_df_hb, y_df_hb, \n",
    "                                                train_size=0.8, \n",
    "                                                random_state=18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hb_predictor = LinearRegression(n_jobs=-1)\n",
    "hb_predictor.fit(X=x_hb_train, y=y_hb_train)\n",
    "\n",
    "predicted_hb = hb_predictor.predict(x_hb_test)\n",
    "nevyazka_hb = hb_predictor.predict(x_hb_train)\n",
    "\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_hb_test, predicted_hb))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(y_hb_test, predicted_hb))\n",
    "plt.scatter(y_hb_train, nevyazka_hb)\n",
    "plt.scatter(y_hb_test, predicted_hb)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = hb_predictor.coef_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    " print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hb_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = [\n",
    "#    \"Энергия деформирования Дж\",\t\n",
    "#    \"Энергия упругого деформирования Дж\",\t\n",
    "#    \"Энергия вязкого деформирования Дж\",\n",
    "#    \"e\",\n",
    "    'Тангенс потерь град',\n",
    "    'P / a', \n",
    "    'Pmax/apmax', \n",
    "    'Pamax/amax',\n",
    "    \"HB\"\n",
    "]\n",
    "df_bf = df[best_features]\n",
    "sns.pairplot(df_bf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df_b = df_bf[\"HB\"]\n",
    "x_df_b = df_bf.drop(columns=\"HB\")\n",
    "\n",
    "x_b_train, x_b_test, y_b_train, y_b_test = train_test_split(x_df_b, y_df_b, \n",
    "                                                train_size=0.8, \n",
    "                                                random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hb_predictor = LinearRegression(n_jobs=-1)\n",
    "hb_predictor.fit(X=x_b_train, y=y_b_train)\n",
    "\n",
    "predicted_hb = hb_predictor.predict(x_b_test)\n",
    "nevyazka_hb = hb_predictor.predict(x_b_train)\n",
    "\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_b_test, predicted_hb))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(y_b_test, predicted_hb))\n",
    "plt.scatter(y_b_train, nevyazka_hb)\n",
    "plt.scatter(y_b_test, predicted_hb)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = hb_predictor.coef_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    " print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
